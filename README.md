# Kaggle_Titanic_Dataset
Repo for Kaggle Titanic Dataset
After a break to finish some courses this is another intorductory competition for me. I will not be using nueral networks in this analysis.

The model at the end of this notebook achieves a score of 72.2% on the Kaggle submission. The untuned Random Forest scored 76.6%. The tuned Random Forest model is clearly overfitting the training set. A previous iteration with a reduced feature set and using a Gradient Boosting Classifier achieved 79.9% accuracy on the submission file.

The notebook is included in this form as I wanted to record the full process I went through. I will now move on to a new data set as I think that will be more beneficial for training purposes than battling to increase my score on this competition.
